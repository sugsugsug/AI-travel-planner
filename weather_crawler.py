# -*- coding: utf-8 -*-
"""travel-planner-crawl.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15brtIzbIKhfJH_A_8zK0lPeE-pbkB6-A

# Dependencies

First, let’s install the required packages:
"""

!pip install langchain langchain-community friendli-client pypdf pymongo langchain-openai tiktoken selenium==4.21.0 selenium-wire==5.1.0 geopy==2.4.1 json2html unstructured

!apt-get update
!apt install chromium-chromedriver
!cp /usr/lib/chromium-browser/chromedriver /usr/bin

from pymongo import MongoClient

MONGODB_ATLAS_CLUSTER_URI = 'mongodb+srv://team-16:wyzhdh3McMrcPtss@cluster0.tyqdayd.mongodb.net/'  # mongodb+srv://team-xx:<password>@cluster0.tyqdayd.mongodb.net/

client = MongoClient(MONGODB_ATLAS_CLUSTER_URI)

DB_NAME = "team-16"
COLLECTION_NAME = "weather"
ATLAS_VECTOR_SEARCH_INDEX_NAME = "team_16_rag_weather"

MONGODB_COLLECTION = client[DB_NAME][COLLECTION_NAME]
client.server_info()

from langchain_community.chat_models.friendli import ChatFriendli
import os

os.environ['FRIENDLI_TOKEN'] = 'flp_uZdkc5WuvEeB0ztSXJjlaeXj3HplqQaUWvMGnTcfT3y5b'
llm = ChatFriendli(model="meta-llama-3-70b-instruct")

"""## Creating a Vector Search Index

To use MongoDB as a vector store, you need to create a vector search index for querying. Configure the search index as follows:
"""

from pymongo.operations import SearchIndexModel

search_model = SearchIndexModel(
    definition={
        "fields": [
            {
                "numDimensions": 1536,
                "path": "embedding",
                "similarity": "cosine",
                "type": "vector"
            }
        ]
    },
    name=ATLAS_VECTOR_SEARCH_INDEX_NAME,
    type="vectorSearch",
)
client[DB_NAME][COLLECTION_NAME].create_search_index(search_model)

"""## Loading Documents and Embeddings

Now, let’s load a document from a PDF file and insert them into MongoDB Atlas with their embeddings. In our case, we’ll load the BPipe paper from the ICML 2023 conference:
"""

from seleniumwire import webdriver
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from seleniumwire.utils import decode
from geopy import geocoders
import datetime
import requests
import html
chrome_options = webdriver.ChromeOptions()
chrome_options.add_argument('--headless')
chrome_options.add_argument('--no-sandbox')
chrome_options.add_argument("--single-process")
chrome_options.add_argument("--disable-dev-shm-usage")

path = "/usr/bin/chromedriver"
driver = webdriver.Chrome(chrome_options = chrome_options)

origin = 'seoul'
destination = 'boston'
start_day = '2024-06-04'
end_day = '2024-06-20'

from langchain_community.document_loaders import TextLoader
from langchain_community.vectorstores import MongoDBAtlasVectorSearch
from langchain_openai import OpenAIEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import BSHTMLLoader
import os

def insert_into_db(html):
    with open('ex.txt', 'w') as f:
        f.write(html)
    # loader = PyPDFLoader("https://openreview.net/pdf?id=HVKmLi1iR4")
    loader = TextLoader('ex.txt')
    data = loader.load()

    text_splitter = RecursiveCharacterTextSplitter(chunk_size=3000, chunk_overlap=150)
    docs = text_splitter.split_documents(data)

    os.environ['OPENAI_API_KEY'] = ''
    vector_store = MongoDBAtlasVectorSearch.from_documents(
        documents=docs,
        embedding=OpenAIEmbeddings(disallowed_special=()),
        collection=MONGODB_COLLECTION,
        index_name=ATLAS_VECTOR_SEARCH_INDEX_NAME,
    )
    retriever = vector_store.as_retriever()
    return retriever

from json2html import *
import json

locations = ['boston', 'london', 'sydney', 'montreal', 'budapest', 'seoul']
gn = geocoders.GeoNames(username='sugsugsug')
retriever = None
for destination in locations:
  loc = gn.geocode(destination)
  r = requests.get(f'https://api.open-meteo.com/v1/forecast?latitude={loc.latitude}&longitude={loc.longitude}&daily=temperature_2m_max,daylight_duration,uv_index_max,precipitation_sum,precipitation_hours&forecast_days=16')
  units = dict(r.json()).get('daily_units')
  times = dict(r.json()).get('daily').get('time') # list
  new_data = {'daily': {time: {} for time in times}}
  for k, v in dict(r.json()).items():
    if k not in ['daily_units', 'daily']:
      new_data[k] = v
    elif k == 'daily':
      for unit in units:
        if unit == 'time':
          continue
        value = v.get(unit)
        for i, time in enumerate(times):
          new_data['daily'][time][unit] = value[i]
  weather_result = "<body>" + json.dumps(new_data) + "</body>"
  weather_result = f"<head><title>{destination}</title></head>" + weather_result
  retriever = insert_into_db(weather_result)

from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import PromptTemplate
from langchain_core.runnables import RunnablePassthrough

template = """Use the following pieces of context to answer the question at the end.
If you don’t know the answer, just say that you don’t know, don’t try to make up an answer.
Use three sentences maximum and keep the answer as concise as possible.
The good weather may refer to not rainy, not cloudy weather.
It would be better if the temperature is around 20 celsius at noon.


{context}

Question: {question}

Helpful Answer:"""

prompt = PromptTemplate.from_template(template)

def format_docs(docs):
    return "\n\n".join(doc.page_content for doc in docs)

COLLECTION_NAME = "weather"
ATLAS_VECTOR_SEARCH_INDEX_NAME = "team_16_rag_weather"
MONGODB_COLLECTION = client[DB_NAME][COLLECTION_NAME]
vector_store = MongoDBAtlasVectorSearch(
    embedding=OpenAIEmbeddings(disallowed_special=()),
    collection=MONGODB_COLLECTION,
    index_name=ATLAS_VECTOR_SEARCH_INDEX_NAME,
)
retriever = vector_store.as_retriever()

rag_chain = (
    {"context": retriever | format_docs, "question": RunnablePassthrough()}
    | prompt
    | llm
    | StrOutputParser()
)

# rag_chain.invoke("What is the memory imbalance problem that BPipe solves?")
# rag_chain.invoke("what is Grace by Nia at Foxwoods ")
# rag_chain.invoke('i want to know Time Out Boston news')
# rag_chain.invoke('i want to know Time Out Boston news')
rag_chain.invoke('Is the weather from 5/28 to 6/3 in Boston good to travel?')
# rag_chain.invoke("Can you recommend some hotels in Boston? I'm planning to travel from 5/28 to 6/3.")
# rag_chain.invoke('Is the weather on 5/25 in Boston good to travel?')

client[DB_NAME][COLLECTION_NAME].delete_many({})

"""Upon execution, you will be able to get the response from the RAG-applied model, which correctly describes the information from the pdf file, despite it being excluded from the data used to train the original model."""
